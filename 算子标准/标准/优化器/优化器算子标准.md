# 优化器算子接口
## 6.1 接口列表
| 类别       | 名称                                                                                                                     |
| ---------- | ------------------------------------------------------------------------------------------------------------------------ |
| 优化器函数 | SGD优化器，Momentum优化器，AdaGrad优化器，AdaDelta优化器，RMSProp优化器，CenteredRMSProp优化器，Adam优化器，AdaMax优化器 |

## 6.2 接口功能和参数
-------------
### 6.2.1 SGD优化器
#### 6.2.1.1 功能描述
SGD优化器，用于更新神经网络中各权重参数。其更新公式如下：

$$param_{out}=param-learning\_rate×grad$$

其中，$grad$表示梯度张量，$param$表示待更新参数，$learning\_rate$表示学习率，$param_{out}$表示更新后的参数。

#### 6.2.1.2 接口参数
| 参数名       | 参数类型 | 可选/必选 | 参数说明                                                     |
| ------------ | -------- | --------- | ------------------------------------------------------------ |
| 待更新参数   | 输入     | 必选      | 输入的待更新参数，元素类型可以为32位浮点数, 64位浮点数       |
| 梯度张量     | 输入     | 必选      | 神经网络训练回传的梯度，元素类型可以为32位浮点数, 64位浮点数 |
| 学习率       | 输入     | 必选      | 参数更新的步长                                               |
| 更新后的参数 | 输出     | 必选      | 更新后的参数张量                                             |

#### 6.2.1.3 接口返回值
没有错误：操作成功。  
类型不匹配：张量的数据类型不一致。

#### 6.2.1.4 引用说明
接口设计参考了TensorFlow、PyTorch、MindSpore、飞桨的接口。

-------------
### 6.2.2 Momentum优化器
#### 6.2.2.1 功能描述
Momentum优化器，用于更新神经网络中各权重参数。其更新公式如下：

$$
\begin{aligned}
& momentum_{out}=momentum\_factor×momentum+grad \\
& if(use\_nesterov): \\
& \qquad param_{out}=param-learning\_rate×(grad+momentum\_factor×momentum_{out}) \\
& else: \\
& \qquad param_{out}=param-learning\_rate×momentum_{out}
\end{aligned}
$$

其中，$grad$表示梯度张量，$param$表示待更新参数，$momentum\_factor$ 表示动量因子，$momentum$ 表示动量，$use\_nesterov$表示使用赋能牛顿动量，$learning\_rate$表示学习率，$momentum_{out}$表示更新后的动量，$param_{out}$表示更新后的参数。

#### 6.2.2.2 接口参数
| 参数名           | 参数类型 | 可选/必选 | 参数说明                                                     |
| ---------------- | -------- | --------- | ------------------------------------------------------------ |
| 待更新参数       | 输入     | 必选      | 输入的待更新参数，元素类型可以为32位浮点数, 64位浮点数       |
| 梯度张量         | 输入     | 必选      | 神经网络训练回传的梯度，元素类型可以为32位浮点数, 64位浮点数 |
| 动量             | 输入     | 必选      | 训练过程中累加的动量                                         |
| 动量因子         | 输入     | 必选      | 计算动量时的衰减率                                           |
| 学习率           | 输入     | 必选      | 参数更新的步长                                               |
| 使用赋能牛顿动量 | 输入     | 必选      | 是否在参数更新过程中使用赋能牛顿动量                         |
| 更新后的参数     | 输出     | 必选      | 更新后的参数张量                                             |
| 更新后的动量     | 输出     | 必选      | 更新后的动量                                                 |

#### 6.2.2.3 接口返回值
没有错误：操作成功。  
类型不匹配：张量的数据类型不一致。

#### 6.2.2.4 引用说明
接口设计参考了TensorFlow、PyTorch、MindSpore、飞桨的接口。

-------------
### 6.2.3 AdaGrad优化器
#### 6.2.3.1 功能描述
AdaGrad优化器，用于更新神经网络中各权重参数。其更新公式如下：

$$
accum_{out}=accum＋ grad^2 \\
param_{out}=param-learning\_rate×\frac{grad}{accum_{out}} 
$$

其中，$grad$表示梯度张量，$param$表示待更新参数，$accum$表示梯度平方和，$accum_{out}$表示更新后的梯度平方和，$learning\_rate$表示学习率， $param_{out}$表示更新后的参数。

#### 6.2.3.2 接口参数
| 参数名             | 参数类型 | 可选/必选 | 参数说明                                                     |
| ------------------ | -------- | --------- | ------------------------------------------------------------ |
| 待更新参数         | 输入     | 必选      | 输入的待更新参数，元素类型可以为32位浮点数, 64位浮点数       |
| 梯度张量           | 输入     | 必选      | 神经网络训练回传的梯度，元素类型可以为32位浮点数, 64位浮点数 |
| 梯度平方和         | 输入     | 必选      | 训练过程中累加的梯度平方和                                   |
| 学习率             | 输入     | 必选      | 参数更新的步长                                               |
| 更新后的参数       | 输出     | 必选      | 更新后的参数张量                                             |
| 更新后的梯度平方和 | 输出     | 必选      | 更新后的梯度平方和                                           |

#### 6.2.3.3 接口返回值
没有错误：操作成功。  
类型不匹配：张量的数据类型不一致。

#### 6.2.3.4 引用说明
接口设计参考了TensorFlow、PyTorch、MindSpore、飞桨的接口。

-------------
### 6.2.4 AdaDelta优化器
#### 6.2.4.1 功能描述
AdaDelta优化器，用于更新神经网络中各权重参数。其更新公式如下：

$$
mean\_square_{out}=α×mean\_square＋(1-α)grad^2 \\
update=\frac{\sqrt{accum\_update+\epsilon}}{\sqrt{mean\_square_{out}+\epsilon}}×grad \\
accum\_update_{out}=α×accum\_update＋(1-α)×update^2 \\
param_{out}=param-learning\_rate×update
$$

其中，$grad$表示梯度张量，$param$表示待更新参数，$mean\_square$表示梯度均方，$mean\_square_{out}$表示更新后的梯度均方，$\alpha$表示衰减率，$accum\_update$表示参数更新量均方，$accum\_update_{out}$表示更新后的参数更新量均方，$learning\_rate$表示学习率，$\epsilon$表示平滑项，$param_{out}$表示更新后的参数。

#### 6.2.4.2 接口参数
| 参数名                 | 参数类型 | 可选/必选 | 参数说明                                                     |
| ---------------------- | -------- | --------- | ------------------------------------------------------------ |
| 待更新参数             | 输入     | 必选      | 输入的待更新参数，元素类型可以为32位浮点数, 64位浮点数       |
| 梯度张量               | 输入     | 必选      | 神经网络训练回传的梯度，元素类型可以为32位浮点数, 64位浮点数 |
| 梯度均方               | 输入     | 必选      | 训练过程中累加的梯度均方                                     |
| 衰减率                 | 输入     | 必选      | 梯度均方和参数更新量均方累加时的衰减率系数                   |
| 参数更新量均方         | 输入     | 必选      | 参数更新量均方                                               |
| 学习率                 | 输入     | 必选      | 参数更新的步长                                               |
| 平滑项                 | 输入     | 必选      | 为了避免除零而加在分母上的小常数                             |
| 更新后的参数           | 输出     | 必选      | 更新后的参数张量                                             |
| 更新后的梯度均方       | 输出     | 必选      | 更新后的梯度均方                                             |
| 更新后的参数更新量均方 | 输出     | 必选      | 更新后的参数更新量均方                                       |

#### 6.2.4.3 接口返回值
没有错误：操作成功。  
类型不匹配：张量的数据类型不一致。

#### 6.2.4.4 引用说明
接口设计参考了TensorFlow、PyTorch、MindSpore、飞桨的接口。

-------------
### 6.2.5 RMSProp优化器
#### 6.2.5.1 功能描述
RMSProp优化器，用于更新神经网络中各权重参数。其更新公式如下：

$$
mean\_square_{out}=α×mean\_square＋ (1-α)grad^2 \\
momentum_{out}=momentum\_factor×momentum+\frac{grad}{\sqrt{mean\_square_{out}+\epsilon}} \\
param_{out}=param-learning\_rate×momentum_{out}
$$

其中，$grad$表示梯度张量，$param$表示待更新参数，$mean\_square$表示梯度均方，$mean\_square_{out}$表示更新后的梯度均方，$\alpha$表示衰减率，$momentum\_factor$表示动量因子，$momentum$表示动量，$momentum_{out}$表示更新后的动量，$learning\_rate$表示学习率，$\epsilon$表示平滑项，$param_{out}$表示更新后的参数。

#### 6.2.5.2 接口参数
| 参数名           | 参数类型 | 可选/必选 | 参数说明                                                     |
| ---------------- | -------- | --------- | ------------------------------------------------------------ |
| 待更新参数       | 输入     | 必选      | 输入的待更新参数，元素类型可以为32位浮点数, 64位浮点数       |
| 梯度张量         | 输入     | 必选      | 神经网络训练回传的梯度，元素类型可以为32位浮点数, 64位浮点数 |
| 梯度均方         | 输入     | 必选      | 训练过程中累加的梯度均方                                     |
| 动量             | 输入     | 必选      | 训练过程中累加的动量                                         |
| 动量因子         | 输入     | 必选      | 计算动量时的衰减率                                           |
| 衰减率           | 输入     | 必选      | 梯度均方累加时历史梯度的系数                                 |
| 学习率           | 输入     | 必选      | 参数更新的步长                                               |
| 平滑项           | 输入     | 必选      | 为了避免除零而加在分母上的小常数                             |
| 更新后的参数     | 输出     | 必选      | 更新后的参数张量                                             |
| 更新后的梯度均方 | 输出     | 必选      | 更新后的梯度均方                                             |
| 更新后的动量     | 输出     | 必选      | 更新后的动量                                                 |

#### 6.2.5.3 接口返回值
没有错误：操作成功。  
类型不匹配：张量的数据类型不一致。

#### 6.2.5.4 引用说明
接口设计参考了TensorFlow、PyTorch、MindSpore、飞桨的接口。

-------------
### 6.2.6 CenteredRMSProp优化器
#### 6.2.6.1 功能描述
CenteredRMSProp优化器，用于更新神经网络中各权重参数，其更新公式如下：

$$
mean\_square_{out}=α×mean\_square＋(1-α)grad^2 \\
mean\_grad_{out}=α×mean\_grad+(1-α)grad \\
momentum_{out}=momentum\_factor×momentum+\frac{grad}{\sqrt{mean\_square_{out}-mean\_grad_{out}^2+\epsilon}} \\
param_{out}=param-learning\_rate×momentum_{out}
$$

其中，$grad$表示梯度张量，$param$表示待更新参数，$mean\_square$表示梯度均方，$mean\_square_{out}$表示更新后的梯度均方，$\alpha$表示衰减率，$mean\_grad$表示平均梯度，$mean\_grad_{out}$表示更新后的平均梯度，$momentum\_factor$ 表示动量因子，$momentum$ 表示动量，$momentum_{out}$表示更新后的动量， $learning\_rate$表示学习率，$\epsilon$表示平滑项，$param_{out}$表示更新后的参数。

#### 6.2.6.2 接口参数
| 参数名           | 参数类型 | 可选/必选 | 参数说明                                                     |
| ---------------- | -------- | --------- | ------------------------------------------------------------ |
| 待更新参数       | 输入     | 必选      | 输入的待更新参数，元素类型可以为32位浮点数, 64位浮点数       |
| 梯度张量         | 输入     | 必选      | 神经网络训练回传的梯度，元素类型可以为32位浮点数, 64位浮点数 |
| 平均梯度         | 输入     | 必选      | 训练过程中累加的平均梯度                                     |
| 梯度均方         | 输入     | 必选      | 训练过程中累加的梯度均方                                     |
| 动量             | 输入     | 必选      | 训练过程中累加的动量                                         |
| 动量因子         | 输入     | 必选      | 计算动量时的衰减率                                           |
| 衰减率           | 输入     | 必选      | 梯度均方累加时历史梯度的系数                                 |
| 学习率           | 输入     | 必选      | 参数更新的步长                                               |
| 平滑项           | 输入     | 必选      | 为了避免除零而加在分母上的小常数                             |
| 更新后的参数     | 输出     | 必选      | 更新后的参数张量                                             |
| 更新后的平均梯度 | 输出     | 必选      | 更新后的平均梯度                                             |
| 更新后的梯度均方 | 输出     | 必选      | 更新后的梯度均方                                             |
| 更新后的动量     | 输出     | 必选      | 更新后的动量                                                 |

#### 6.2.6.3 接口返回值
没有错误：操作成功。  
类型不匹配：张量的数据类型不一致。

#### 6.2.6.4 引用说明
接口设计参考了TensorFlow、PyTorch、MindSpore、飞桨的接口。

-------------
### 6.2.7 Adam优化器
#### 6.2.7.1 功能描述
Adam优化器，用于更新神经网络中各权重参数。其更新公式如下：

$$
m_{out}=β_1×m＋(1-β_1)×grad \\
v_{out}=β_2×v＋(1-β_2)×grad^2 \\
m_{bias}=\frac{m_{out}}{1-β\_power_1} \\
v_{bias}=\frac{v_{out}}{1-β\_power_2} \\
param_{out}=param-learning\_rate×\frac{m_{bias}}{\sqrt{v_{bias}}+\epsilon}
$$

其中，$grad$表示梯度张量，$param$表示待更新参数，$m$表示动量一，$v$表示动量二，$β_1$表示衰减率一，$β_2$表示衰减率二，$m_{out}$表示更新后的动量一，$v_{out}$表示更新后的动量二，$β\_power_1$表示衰减率一的幂，$β\_power_2$表示衰减率二的幂，$learning_rate$表示学习率，$\epsilon$表示平滑项，$param_{out}$表示更新后的参数。

#### 6.2.7.2 接口参数
| 参数名         | 参数类型 | 可选/必选 | 参数说明                                                     |
| -------------- | -------- | --------- | ------------------------------------------------------------ |
| 待更新参数     | 输入     | 必选      | 输入的待更新参数，元素类型可以为32位浮点数, 64位浮点数       |
| 梯度张量       | 输入     | 必选      | 神经网络训练回传的梯度，元素类型可以为32位浮点数, 64位浮点数 |
| 动量一         | 输入     | 必选      | 训练过程中累加的动量一                                       |
| 动量二         | 输入     | 必选      | 训练过程中累加的动量二                                       |
| 衰减率一       | 输入     | 必选      | 计算动量一时的衰减率                                         |
| 衰减率二       | 输入     | 必选      | 计算动量二时的衰减率                                         |
| 衰减率一的幂   | 输入     | 必选      | 衰减率一的幂                                                 |
| 衰减率二的幂   | 输入     | 必选      | 衰减率二的幂                                                 |
| 学习率         | 输入     | 必选      | 参数更新的步长                                               |
| 平滑项         | 输入     | 必选      | 为了避免除零而加在分母上的小常数                             |
| 更新后的参数   | 输出     | 必选      | 更新后的参数张量                                             |
| 更新后的动量一 | 输出     | 必选      | 更新后的动量一                                               |
| 更新后的动量二 | 输出     | 必选      | 更新后的动量二                                               |

#### 6.2.7.3 接口返回值
没有错误：操作成功。  
类型不匹配：张量的数据类型不一致。

#### 6.2.7.4 引用说明
接口设计参考了TensorFlow、PyTorch、MindSpore、飞桨的接口。

-------------
### 6.2.8 AdaMax优化器
#### 6.2.8.1 功能描述
AdaMax优化器算子，用于更新神经网络中各权重参数，其更新公式如下：

$$
mean\_grad_{out}=α×mean\_grad+(1-α)*grad \\
grad\_max_{out}=max⁡(\beta×grad\_max,|grad|) \\
param_{out}=param-\frac{mean\_grad_{out}}{(grad\_max_{out}+\epsilon)×(1-α\_power)}×learning\_rate
$$

其中，$param$表示待更新参数，$grad$表示梯度张量，$\alpha$表示平均梯度衰减率，$α\_power$表示平均梯度衰减率的幂，$\beta$表示梯度最大值衰减率，$mean\_grad$表示平均梯度，$mean\_grad_{out}$表示更新后的平均梯度，$grad\_max$表示梯度最大值，$grad\_max_{out}$表示更新后的梯度最大值，$learning\_rate$表示学习率，$\epsilon$表示平滑项，$param_{out}$表示更新后的参数。

#### 6.2.8.2 接口参数
| 参数名             | 参数类型 | 可选/必选 | 参数说明                                                     |
| ------------------ | -------- | --------- | ------------------------------------------------------------ |
| 待更新参数         | 输入     | 必选      | 输入的待更新参数，元素类型可以为32位浮点数, 64位浮点数       |
| 梯度张量           | 输入     | 必选      | 神经网络训练回传的梯度，元素类型可以为32位浮点数, 64位浮点数 |
| 平均梯度           | 输入     | 必选      | 训练过程中累加的平均梯度                                     |
| 平均梯度衰减率     | 输入     | 必选      | 计算平均梯度时使用的衰减率                                   |
| 平均梯度衰减率的幂 | 输入     | 必选      | 计算平均梯度时使用的衰减率的幂                               |
| 梯度最大值衰减率   | 输入     | 必选      | 计算梯度最大值时使用的衰减率                                 |
| 梯度最大值         | 输入     | 必修      | 梯度最大值                                                   |
| 学习率             | 输入     | 必选      | 参数更新的步长                                               |
| 平滑项             | 输入     | 必选      | 为了避免除零而加在分母上的小常数                             |
| 更新后的参数       | 输出     | 必选      | 更新后的参数张量                                             |
| 更新后的平均梯度   | 输出     | 必选      | 更新后的平均梯度                                             |
| 更新后的梯度最大值 | 输出     | 必选      | 更新后的梯度最大值                                           |

#### 6.2.8.3 接口返回值
没有错误：操作成功。  
类型不匹配：张量的数据类型不一致。

#### 6.2.8.4 引用说明
接口设计参考了TensorFlow、PyTorch、MindSpore、飞桨的接口。

-------------